{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7JpzHOafO49b",
        "outputId": "027d7477-eef4-4337-ff0f-bae37a9a435d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100%|██████████| 97.8M/97.8M [00:00<00:00, 243MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Load pre-trained ResNet-50 model\n",
        "resnet = models.resnet50(pretrained=True)\n",
        "\n",
        "# Remove the fully connected layer and use the output of the last convolutional layer\n",
        "class ResNetFeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNetFeatureExtractor, self).__init__()\n",
        "        self.resnet = nn.Sequential(*list(resnet.children())[:-1])  # Remove the last FC layer\n",
        "\n",
        "    def forward(self, images):\n",
        "        features = self.resnet(images)\n",
        "        features = features.view(features.size(0), -1)  # Flatten to (batch_size, 2048)\n",
        "        return features\n",
        "\n",
        "# Example usage:\n",
        "# resnet_feature_extractor = ResNetFeatureExtractor()\n",
        "# image_features = resnet_feature_extractor(images)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers=1):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, features, captions):\n",
        "        embeddings = self.embed(captions)\n",
        "        embeddings = torch.cat((features.unsqueeze(1), embeddings), 1)\n",
        "        lstm_out, _ = self.lstm(embeddings)\n",
        "        outputs = self.linear(lstm_out)\n",
        "        return outputs\n",
        "\n",
        "# Example usage:\n",
        "# decoder_rnn = DecoderRNN(embed_size, hidden_size, vocab_size, num_layers)\n",
        "# outputs = decoder_rnn(image_features, captions)\n"
      ],
      "metadata": {
        "id": "Ilt7JVlpPrAU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class DecoderRNN(nn.Module):\n",
        "    def __init__(self, embed_size, hidden_size, vocab_size, num_layers=1):\n",
        "        super(DecoderRNN, self).__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, embed_size)\n",
        "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
        "\n",
        "    def forward(self, features, captions):\n",
        "        embeddings = self.embed(captions)\n",
        "        embeddings = torch.cat((features.unsqueeze(1), embeddings), 1)\n",
        "        lstm_out, _ = self.lstm(embeddings)\n",
        "        outputs = self.linear(lstm_out)\n",
        "        return outputs\n",
        "\n",
        "# Example usage:\n",
        "# decoder_rnn = DecoderRNN(embed_size, hidden_size, vocab_size, num_layers)\n",
        "# outputs = decoder_rnn(image_features, captions)\n"
      ],
      "metadata": {
        "id": "tHnKu_xmPva7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for images, captions in train_loader:\n",
        "        images = images.to(device)\n",
        "        captions = captions.to(device)\n",
        "\n",
        "        # Zero the gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        features = resnet_feature_extractor(images)\n",
        "        outputs = decoder_rnn(features, captions)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs.view(-1, vocab_size), captions.view(-1))\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Print training statistics\n",
        "        if (i+1) % print_every == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                  .format(epoch+1, num_epochs, i+1, total_steps, loss.item()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "tcDO_XHmQGPT",
        "outputId": "a651f37d-e6d6-45ad-de5c-b85a425fdb5e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-7e9817ae542d>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Define your loss function and optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install torch torchvision\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0r8t36eQ5Zc",
        "outputId": "ed78ae6f-945e-42d0-d9a8-90eaa8f296ac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "from torch.utils.data import DataLoader\n",
        "\n"
      ],
      "metadata": {
        "id": "nnKkgCRWRxMj"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),  # Convert PIL image or numpy array to tensor\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize to range [-1, 1]\n",
        "])\n",
        "\n",
        "# Load MNIST dataset\n",
        "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGO55Ka7R197",
        "outputId": "563eccac-6b05-4830-9b64-5a0a3052b40a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:01<00:00, 8412341.81it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 1132617.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 7555741.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 12863287.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple neural network model\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
        "        self.fc2 = nn.Linear(128, 10)\n",
        "        self.dropout = nn.Dropout(0.25)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 7 * 7)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Create an instance of the model\n",
        "model = SimpleCNN()\n"
      ],
      "metadata": {
        "id": "aqyxOp6SR-uD"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ],
      "metadata": {
        "id": "W-mHNZE4SBuy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if (batch_idx+1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}')\n",
        "            running_loss = 0.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_sel6tRSFUz",
        "outputId": "acfaa98d-6051-407e-8c7e-3f0f85a2458a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/938], Loss: 0.7636\n",
            "Epoch [1/10], Step [200/938], Loss: 0.2268\n",
            "Epoch [1/10], Step [300/938], Loss: 0.1646\n",
            "Epoch [1/10], Step [400/938], Loss: 0.1365\n",
            "Epoch [1/10], Step [500/938], Loss: 0.1129\n",
            "Epoch [1/10], Step [600/938], Loss: 0.1067\n",
            "Epoch [1/10], Step [700/938], Loss: 0.0844\n",
            "Epoch [1/10], Step [800/938], Loss: 0.0937\n",
            "Epoch [1/10], Step [900/938], Loss: 0.0943\n",
            "Epoch [2/10], Step [100/938], Loss: 0.0793\n",
            "Epoch [2/10], Step [200/938], Loss: 0.0713\n",
            "Epoch [2/10], Step [300/938], Loss: 0.0777\n",
            "Epoch [2/10], Step [400/938], Loss: 0.0745\n",
            "Epoch [2/10], Step [500/938], Loss: 0.0648\n",
            "Epoch [2/10], Step [600/938], Loss: 0.0539\n",
            "Epoch [2/10], Step [700/938], Loss: 0.0653\n",
            "Epoch [2/10], Step [800/938], Loss: 0.0559\n",
            "Epoch [2/10], Step [900/938], Loss: 0.0574\n",
            "Epoch [3/10], Step [100/938], Loss: 0.0513\n",
            "Epoch [3/10], Step [200/938], Loss: 0.0478\n",
            "Epoch [3/10], Step [300/938], Loss: 0.0515\n",
            "Epoch [3/10], Step [400/938], Loss: 0.0493\n",
            "Epoch [3/10], Step [500/938], Loss: 0.0463\n",
            "Epoch [3/10], Step [600/938], Loss: 0.0607\n",
            "Epoch [3/10], Step [700/938], Loss: 0.0502\n",
            "Epoch [3/10], Step [800/938], Loss: 0.0523\n",
            "Epoch [3/10], Step [900/938], Loss: 0.0523\n",
            "Epoch [4/10], Step [100/938], Loss: 0.0472\n",
            "Epoch [4/10], Step [200/938], Loss: 0.0442\n",
            "Epoch [4/10], Step [300/938], Loss: 0.0445\n",
            "Epoch [4/10], Step [400/938], Loss: 0.0406\n",
            "Epoch [4/10], Step [500/938], Loss: 0.0386\n",
            "Epoch [4/10], Step [600/938], Loss: 0.0481\n",
            "Epoch [4/10], Step [700/938], Loss: 0.0459\n",
            "Epoch [4/10], Step [800/938], Loss: 0.0395\n",
            "Epoch [4/10], Step [900/938], Loss: 0.0396\n",
            "Epoch [5/10], Step [100/938], Loss: 0.0308\n",
            "Epoch [5/10], Step [200/938], Loss: 0.0347\n",
            "Epoch [5/10], Step [300/938], Loss: 0.0388\n",
            "Epoch [5/10], Step [400/938], Loss: 0.0335\n",
            "Epoch [5/10], Step [500/938], Loss: 0.0357\n",
            "Epoch [5/10], Step [600/938], Loss: 0.0370\n",
            "Epoch [5/10], Step [700/938], Loss: 0.0393\n",
            "Epoch [5/10], Step [800/938], Loss: 0.0346\n",
            "Epoch [5/10], Step [900/938], Loss: 0.0411\n",
            "Epoch [6/10], Step [100/938], Loss: 0.0346\n",
            "Epoch [6/10], Step [200/938], Loss: 0.0286\n",
            "Epoch [6/10], Step [300/938], Loss: 0.0282\n",
            "Epoch [6/10], Step [400/938], Loss: 0.0389\n",
            "Epoch [6/10], Step [500/938], Loss: 0.0262\n",
            "Epoch [6/10], Step [600/938], Loss: 0.0332\n",
            "Epoch [6/10], Step [700/938], Loss: 0.0375\n",
            "Epoch [6/10], Step [800/938], Loss: 0.0309\n",
            "Epoch [6/10], Step [900/938], Loss: 0.0286\n",
            "Epoch [7/10], Step [100/938], Loss: 0.0220\n",
            "Epoch [7/10], Step [200/938], Loss: 0.0272\n",
            "Epoch [7/10], Step [300/938], Loss: 0.0282\n",
            "Epoch [7/10], Step [400/938], Loss: 0.0254\n",
            "Epoch [7/10], Step [500/938], Loss: 0.0288\n",
            "Epoch [7/10], Step [600/938], Loss: 0.0281\n",
            "Epoch [7/10], Step [700/938], Loss: 0.0268\n",
            "Epoch [7/10], Step [800/938], Loss: 0.0298\n",
            "Epoch [7/10], Step [900/938], Loss: 0.0274\n",
            "Epoch [8/10], Step [100/938], Loss: 0.0282\n",
            "Epoch [8/10], Step [200/938], Loss: 0.0194\n",
            "Epoch [8/10], Step [300/938], Loss: 0.0214\n",
            "Epoch [8/10], Step [400/938], Loss: 0.0215\n",
            "Epoch [8/10], Step [500/938], Loss: 0.0268\n",
            "Epoch [8/10], Step [600/938], Loss: 0.0256\n",
            "Epoch [8/10], Step [700/938], Loss: 0.0243\n",
            "Epoch [8/10], Step [800/938], Loss: 0.0299\n",
            "Epoch [8/10], Step [900/938], Loss: 0.0337\n",
            "Epoch [9/10], Step [100/938], Loss: 0.0169\n",
            "Epoch [9/10], Step [200/938], Loss: 0.0232\n",
            "Epoch [9/10], Step [300/938], Loss: 0.0239\n",
            "Epoch [9/10], Step [400/938], Loss: 0.0279\n",
            "Epoch [9/10], Step [500/938], Loss: 0.0205\n",
            "Epoch [9/10], Step [600/938], Loss: 0.0291\n",
            "Epoch [9/10], Step [700/938], Loss: 0.0262\n",
            "Epoch [9/10], Step [800/938], Loss: 0.0284\n",
            "Epoch [9/10], Step [900/938], Loss: 0.0242\n",
            "Epoch [10/10], Step [100/938], Loss: 0.0220\n",
            "Epoch [10/10], Step [200/938], Loss: 0.0268\n",
            "Epoch [10/10], Step [300/938], Loss: 0.0173\n",
            "Epoch [10/10], Step [400/938], Loss: 0.0215\n",
            "Epoch [10/10], Step [500/938], Loss: 0.0257\n",
            "Epoch [10/10], Step [600/938], Loss: 0.0210\n",
            "Epoch [10/10], Step [700/938], Loss: 0.0161\n",
            "Epoch [10/10], Step [800/938], Loss: 0.0246\n",
            "Epoch [10/10], Step [900/938], Loss: 0.0240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(f'Accuracy on the test set: {100 * correct / total}%')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8OeQugbURnC",
        "outputId": "0ce21327-5991-471d-e325-aafda37e0176"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on the test set: 99.4%\n"
          ]
        }
      ]
    }
  ]
}